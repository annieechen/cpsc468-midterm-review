\documentclass[10pt]{article}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{algorithmicx}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{graphicx}
\usepackage{float}
\usepackage{ulem}
\usepackage{hyperref}
\hypersetup{
  colorlinks=true,
  linkcolor=blue,
}
% \usepackage{listings,lstautogobble}
\geometry{margin=0.75in}
\setlength\parindent{0pt}

\title{CPSC 468 Midterm Review}
\author{}
\date{}

\mathchardef\mhyphen="2D

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{claim}{Claim}[section]
\newtheorem{example}{Example}[section]
\newtheorem{note}{}[section]

\begin{document}
\maketitle

\newcommand{\E}{\mathrm{E}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\Real}{\mathrm{Re}}
\newcommand{\Imag}{\mathrm{Im}}
\newcommand{\res}{\mathrm{res}}
\newcommand{\NP}{\mathrm{NP}}
\newcommand{\NPC}{\mathrm{NP\mhyphen Complete}}
\newcommand{\coNP}{\mathrm{coNP}}
\newcommand{\coNPC}{\mathrm{coNP\mhyphen Complete}}
\newcommand{\DP}{\mathrm{DP}}
\newcommand{\PTIME}{\mathrm{P}}
\newcommand{\AL}{\mathrm{AL}}
\newcommand{\INDSET}{\mathrm{INDSET}}
\newcommand{\NOTINDSET}{\overline{\mathrm{INDSET}}}
\newcommand{\EXACTINDSET}{\mathrm{EXACT\mhyphen INDSET}}
\newcommand{\SAT}{\mathrm{SAT}}
\newcommand{\UNSAT}{\overline{\mathrm{SAT}}}
\newcommand{\TMSAT}{\mathrm{TMSAT}}
\newcommand{\ACCEPT}{\mathrm{ACCEPT}}
\newcommand{\REJECT}{\mathrm{REJECT}}
\newcommand{\DTIME}{\mathrm{DTIME}}
\newcommand{\NTIME}{\mathrm{NTIME}}
\newcommand{\EXP}{\mathrm{EXP}}
\newcommand{\NEXP}{\mathrm{NEXP}}
\newcommand{\SPACE}{\mathrm{SPACE}}
\newcommand{\PSPACE}{\mathrm{PSPACE}}
\newcommand{\NSPACE}{\mathrm{NSPACE}}

\newcommand{\st}{\mathrm{\ s.t.\ }}

\subsection*{Chapter 1: The Computational Model and Why It Doesn't Matter}
\begin{note}[Turing Machine]
  A $k$-tape Turing Machine $M$ is described by a tuple $(\Gamma, Q, \delta)$.
  Assume $k \geq 2$, with $1$ read-only input tape and $k - 1$ work tapes.
  The last work tape is assumed to be the output tape.
  \begin{itemize}
    \item
      $\Gamma$ the finite alphabet of symbols that $M$ may have on its tapes.
      Assume that $\Gamma$ contains at least $\{0,1,\square,\triangleright\}$.

    \item
      $Q$ a finite set of possible states $M$'s state register may be in.
      Assume that $Q$ contains a $q_{start}$ and $q_{halt}$.

    \item
      $\delta : Q \times \Gamma^k \to Q
      \times \Gamma^{k - 1} \times \{L, S, R\}^k$ a transition function for
      $M$ that takes in the current state and each head's read, and outputs
      the next state, with $k - 1$ writes on all the work tapes, and movements
      for all $k$ tapes.
  \end{itemize}
\end{note}

\begin{note}[Computing a Function]
  Let $f : \{0, 1\}^\ast \to \{0, 1\}^\ast$ and
  $T : \mathbb{N} \to \mathbb{N}$, with $M$ a TM.
  We say that $M$ computes $f$ if for every $x \in \{0, 1\}^\ast$, if
  $M$ is initialized to the start configuration on input $x$, then it halts
  with $f(x)$ on the output tape.
  We say $M$ computes $f$ in $T(n)$-time if its computation on every
  $x$ requires at most $T(|x|)$ steps.
\end{note}

\begin{note}[Time Constructible]
  A function $T: \mathbb{N} \to \mathbb{N}$ is time constructible if
  $T(n) \geq n$ and there is a TM $M$ that computes the function
  $x \mapsto \llcorner T(|x|) \lrcorner$ in time $T(n)$.
  $T(n) \geq n$ is to allow the algorithm to read its input.
  Some time constructible functions are $n$, $n \log n$, $n^2$ and $2^n$.
\end{note}

\begin{note}
  For every $f : \{0, 1\}^\ast \to \{0, 1\}$ and time constructible
  $T : \mathbb{N} \to \mathbb{N}$, if $f$ is computable in time $T(n)$ by
  some TM $M$ using alphabet $\Gamma$, then it is able to compute the same
  function using $\{0, 1, \square, \triangleright\}$ in 
  $\left(c \log_2 | \Gamma| \right) \cdot T(n)$.
  This is because we may express each symbol of $\Gamma$ using
  $\log |\Gamma|$ binary bits, with some constant $c$ overhead.
\end{note}

\begin{note}
  A $k$-tape TM can have its $k - 1$ work tapes simulated by a single tape by
  interleaving the $k$ tapes together.
\end{note}

\begin{note}[Oblivious Turing Machine]
  An oblivious TM's head movement depends on the length of the input, not
  the contents of the input.
  Every TM can be simulated by an oblivious TM.
\end{note}

\begin{note}[Turing Machine Representation]
  Every binary string $x \in \{0, 1\}^\ast$ represents some TM, and every TM
  is represented by infinite such strings (think: comments in a language).
  The machine represented by $x$ is denoted $M_x$.
\end{note}

\begin{note}[Universal Turing Machine]
  There exists a TM $\mathcal{U}$ such that for every
  $x, \alpha \in \{0, 1\}^\ast$, $\mathcal{U}(x, a) = M_\alpha (x)$, where
  $M_\alpha$ denotes the TM represented by $\alpha$.
  Moreover, if $M_\alpha$ halts on input $x$ within $T$ steps, then
  $\mathcal{U}_\alpha (x)$ halts within $C T \log T$ steps, where $C$ is
  a number independent of $|x|$, and depends only on $M_\alpha$'s alphabet
  size, number of tapes, and number of states.
  The cost of simulating any machine $M_\alpha$ has a
  logarithmic overhead, due to the alphabet size difference between
  $M_\alpha$ and $\mathcal{U}$.
  As $\mathcal{U}$ has a single tape, we do the trick over interleaving
  $M_\alpha$'s work tapes together.
\end{note}

\begin{note}[Uncomputable Function]
  Define $U$ as follows: for every $\alpha \in \{0, 1\}^\ast$, if the machine
  defined by $\alpha$ accepts itself, such that $M_\alpha (\alpha) = 1$, then
  $U(\alpha) = 0$.
  In other words $U(\alpha) = 1 - M_\alpha (\alpha)$.
  There is no such TM that can compute $U$, because $U$ will always negate it.
\end{note}

\begin{note}[Halting Problem]
  A TM $H$ such that $H(\alpha, x) = 1$ if $M_\alpha (x)$ halts, and yields
  $0$ otherwise, does not exist.
  We can construct a wrapper TM $W$ that invokes $H$ on itself, and performs
  the opposite.
  Diagonalization motherfuckers!
\end{note}

\begin{note}[$\DTIME$]
  Let $T : \mathbb{N} \to \mathbb{N}$ be some function.
  A language $L$ is in $\DTIME(T(n))$ iff there is a deterministic
  TM that runs in time
  $c \cdot T(n)$ for some constant $c > 0$ and decides $L$.
  This class contains \textbf{decision} problems.
\end{note}

\begin{note}[The Class $\PTIME$]
  $\PTIME = \bigcup_{c \geq 1} \DTIME(n^c)$
\end{note}

\begin{note}[Church-Turing Thesis]
  Every physically realizable computation device can be simulated by a TM.
\end{note}

\begin{note}[Bounds]
  The asymptoptic operators $\{o, O, \Theta, \Omega, \omega\}$ can be thought
  of as $\{ <, \leq, =, \geq, > \}$.
\end{note}

\subsection*{Chapter 2: $\NP$ and $\NP$ Completeness}
\begin{note}[Non-deterministic Turing Machine]
  A non-deterministic TM is endowed with two transition functions
  $\delta_0$ and $\delta_1$ along with a special accept state $q_{accept}$.
  The NDTM may use either transition function per time step.
  For every input $x$, we say that $M(x) = 1$ if there \textbf{exists}
  some sequence of transition function choises
  that would cause $M$ to reach $q_{accept}$.
  Otherwise, if every sequence of non-deterministic choices causes $M$ to halt
  on $x$ without reaching $q_{accept}$, then we say that $M(x) = 0$.
  $M$ runs in time $T(n)$ if for every input $x \in \{0, 1\}^\ast$ and every
  sequence of non-deterministic choices, $M$ reaches eitehr the halting state
  or $q_{accept}$ within $T(|x|)$ steps.
\end{note}

\begin{note}[$\NTIME$]
  For every function $T : \mathbb{N} \to \mathbb{N}$ and
  $L \subseteq \{0, 1\}^\ast$, we say that $L \in \NTIME(T(n))$ if there is
  a constant $c > 0$ and a $c \cdot T(n)$-time NDTM $M$ such that for
  every $x \in \{0, 1\}^\ast$, we have $x \in L \iff M(x) = 1$.
\end{note}

\begin{note}[$\NP$]
  $\NP = \bigcup_{c \in \mathbb{N}} \NTIME(n^c)$
\end{note}

\begin{note}[]
  A language $L \subseteq \{0, 1\}^\ast$ is in $\NP$ if there exists a
  polynomial $p : \mathbb{N} \to \mathbb{N}$ and a polynomial time TM $M$
  (called the \textbf{verifier} for $L$) $\st$ for every
  $x \in \{0, 1\}^\ast$, we have
  $x \in L \iff \exists u \in \{0, 1\}^{p(|x|)} \st M(x, u) = 1$.
  If $x \in L$ and $u \in \{0, 1\}^{p(|x|)}$ satisfy $M(x, u) = 1$,
  we call $u$ a \textbf{certificate} for $x$ (with respect to $L$ and $M$).
  $\NP$ is the class of languages for which we can tell if
  $u$ is a solution to the problem $x \in L$ in polynomial time.
\end{note}

\begin{note}[Reductions, $\NP$-hardness, and $\NP$-completeness]
  We say that a language $L \subseteq \{0, 1\}^\ast$ is a polynomial time
  \textbf{Karp reducible} to a language $L^\prime \subseteq \{0, 1\}^\ast$ if
  there is a polynomial time computable function
  $f : \{0, 1\}^\ast \to \{0, 1\}^\ast$ such that for
  every $x \in \{0, 1\}^\ast$, we have $x \in L \iff f(x) \in L^\prime$.
  We say that $L^\prime$ is $\NP$-hard if $L \leq_p L^\prime$ for every
  $L \in \NP$.
  We say that $L^\prime$ is $\NP$-complete if $L^\prime$ is $\NP$-hard and
  $L^\prime \in \NP$.
\end{note}

\begin{note}[Cook Reduction]
  A reduction computed by a deterministic polynomial time oracle TM.
\end{note}

\begin{note}[Transitivity]
  If $L \leq_p L^\prime$, and $L^\prime \leq_p L^{\prime \prime}$, then
  $L \leq_p L^{\prime \prime}$.
\end{note}

\begin{note}
  If $L$ is $\NP$-hard and $L \in \PTIME$, then $\PTIME = \NP$.
\end{note}

\begin{note}
  If $L$ is $\NPC$ then $L \in \PTIME \iff \PTIME = \NP$.
\end{note}

\begin{note}[TMSAT]
  $\TMSAT = \{ (\alpha, x, 1^n, 1^t) :
    \text{$\exists u \in \{0, 1\}^n \st
          M_a (x, u) = 1$ within $t$ steps} \}$
\end{note}

\begin{note}[Decision vs Search]
  Suppose that $\PTIME = \NP$, then for every $\NP$ language $L$ there exists
  a polynomial time TM $B$ such that on input $x \in L$ outputs a certificate
  for $x$.
  That is, $x \in L \iff \exists u \in \{ 0, 1\}^{p(|x|)} \st M(x, u) = 1$
  where $p$ is some polynomial and $M$ is a polynomial time TM, then on
  input $x \in L$, we have $B(x)$ as the string $u \in \{0, 1\}^{p(|x|)}$
  satisfying $M(x, B(x)) = 1$.
\end{note}

\begin{note}[Complement Language]
  If $L \subseteq \{0, 1\}^\ast$, then we denote $\overline{L}$ to be the
  complement of $L$.
  That is, $\overline{L} = \{0, 1\}^\ast \setminus L$.
\end{note}

\begin{note}[$\coNP$]
  $\coNP = \{L : \overline{L} \in \NP\}$
\end{note}

\begin{note}[$\coNP$ Alternative Definition]
  For every $L \subseteq \{0, 1\}^\ast$, we say $L \in \coNP$ if there
  is a polynomial $p : \mathbb{N} \to \mathbb{N}$ and a polynomial time
  TM $M$ $\st$ for every $x \in \{0, 1\}^\ast$, we have
  $x \in L \iff \forall u \in \{0, 1\}^{p(|x|)}$ with $M(x, u) = 1$.
\end{note}

\begin{note}
  $\coNP$ is the class of problems for which we can reject proposed solutions
  in polynomial time.
\end{note}

\begin{note}
  $\PTIME \subseteq \NP \cap \coNP$
\end{note}

\begin{note}[$\EXP$]
  $\EXP = \bigcup_{c \geq 1} \DTIME\left(2^{n^c}\right)$
\end{note}

\begin{note}[$\NEXP$]
  $\NEXP = \bigcup_{c \geq 1} \NTIME\left(2^{n^c}\right)$
\end{note}


\subsection*{Chapter 3: Diagonalization}
\begin{note}[Main Idea]
  For two complexity classes $C_1$ and $C_2$, we show
  $C_1 \subsetneq C_2$ by presenting $L \st L \in C_2$ but $L \not\in C_1$.
\end{note}

\begin{note}[Time Hierarchy Theorem]
  If $f, g$ are time constructible function satisfying
  $f(n) \log f(n) = o (g(n))$, then we have
  $\DTIME(f(n)) \subsetneq \DTIME(g(n))$.
\end{note}

\begin{note}[Sketch for $\DTIME(n) \subsetneq \DTIME\left(n^{1.5}\right)$]
  For the ``diagonal'' machine $D$:
  on input $x$ run for $|x|^{1.4}$ steps on the universal TM $\mathcal{U}$
  to simulate $M_x (x)$.
  If $\mathcal{U}$ outputs a bit $b \in \{0, 1\}$, we yield the opposite,
  which is $1 - b$, and $0$ if it fails to halt in time $|x|^{1.4}$.
  By definition, $D$ always halts within $n^{1.4}$ steps and so any language
  decided by $D$ is in $\DTIME\left(n^{1.5}\right)$.
  There is no machine $M$ that always halts within $n$ steps that can emulate
  $D$ because $D$ will have captured its result and yielded the opposite.
  Thus, $L \in \DTIME\left(n^{1.5}\right)$, but $L \not\in \DTIME(n)$.
\end{note}

\begin{note}[Non-deterministic Time Hierarchy Theorem]
  If $f, g$ are time constructible funcitons satisfying the bound
  $f(n + 1) = o(g(n))$,
  then $\NTIME(f(n)) \subsetneq \NTIME(g(n))$.
\end{note}

\begin{note}[Sketch for $\NTIME(n) \subsetneq \NTIME\left(n^{1.5}\right)$]
Apply lazy diagonalization.
Define $f : \mathbb{N} \to \mathbb{N}$ as follows: $f(1) = 2$
and $f(i + 1) = 2^{f(i)^{1.2}}$.
We will find some $n$ such that $f(i) < n \leq f(i + 1)$.
The goal for our diagonal machine is to flip the result on the
set $\{ 1^n : f(i) < n \leq f(i + 1)\}$.
Define $D$ as:
If (1) $f(i) < n < f(i + 1)$ then simulate $M_i$ on input $1 ^{n + 1}$ using
non-determinism in $n^{1.1}$ time and output.
Otherwise if (2) $n = f(i + 1)$ accept $1^n$ iff $M_i$ rejects
$1^{f(i) + 1}$ in $(f(i) + 1)^{1.1}$ time.
Thus, if $f(i) < n < f(i + 1)$ then
$D\left(1^n\right) = M_i \left(1^{n + 1}\right)$, otherwise
$D\left(1^{f(i + 1)}\right) \neq M_i \left(1^{f(i) + 1}\right)$.
\end{note}

\begin{note}[Ladner's Theorem]
  Suppose that $\PTIME \neq \NP$, then there exists a language
  $L \in \NP \setminus \PTIME$ that is not $\NPC$.
\end{note}

\begin{note}[Sketch for Ladner's Theorem]
  We make some $L \in \NP \setminus \PTIME$ ``easy enough'' using padding so
  that it is no longer $\NPC$, while keeping it ``hard enough'' so that it is
  not $\PTIME$.
  We do this by taking an $\NPC$ language and ``blowing holdes'' in it.
\end{note}

\subsection*{Chapter 4: Space Complexity}
\begin{note}[Space-bounded Computation]
  Let $S : \mathbb{N} \to \mathbb{N}$ and $L \subseteq \{0, 1\}^\ast$.
  We say that $L \in \SPACE(s(n))$ if there is a constant $c$ and
  a deterministic TM $M$ that
  decides $L$ with at most $c \cdot s(n)$ locations on
  $M$'s work tapes (excluding the input tape) are ever visited by $M$'s head 
  during its computation on every input of length $n$.
  Likewise, say that $L \in \NSPACE(s(n))$ if there is an NDTM $M$ deciding
  $L$ that never uses more than $c \cdot s(n)$ non-blank tape locations on
  length $n$ inputs, regardless of its non-deterministic choices.
\end{note}

\begin{note}
  $\DTIME(S(n)) \subseteq \SPACE(S(n))$ since a TM can access only one
  tape cell per step, so a $\SPACE(S(n))$ TM can run for much longer than
  $S(n)$ steps.
  In fact, halting behavior can run for as much as $2^{\Omega (S(n))}$ steps
  -- as an example, a counter machine that counts from $1$ to
  $2^{S(n) - 1}$.
  Any language that is in $\SPACE(S(n))$ is
  in $\DTIME\left(2^{O(S(n))}\right)$.
\end{note}

\begin{note}
  For space constructible $S: \mathbb{N} \to \mathbb{N}$:
  $\DTIME(S(n)) \subseteq \SPACE(S(n)) \subseteq \NSPACE(S(n))
  \subseteq \DTIME\left(2^{O(S(n))}\right)$
\end{note}

\begin{note}[Configuration Graph]
  A configuration of a TM $M$ consists of the contents of all non-blank
  entries on $M$'s tapes, along with its state and head position at a
  particular point in execution.
  For eveyr space $S(n)$ TM $M$ and input $x \in \{0, 1\}^\ast$, the
  configuration graph of $M$ on nput $x$, denote $G_{M, x}$ is a directed
  graph whose nodes correspond to all possible configurations of $M$, where
  the input contains the value $x$ and the work tapes have at most $S(|x|)$
  non-blank cells.
  The graph has a directed edge from a configuration $C$ to a configuration
  $C^\prime$ if $C^\prime$ can be reached from $C$ in one step according
  to $M$'s transition function.
  If $M$ is deterministic, then the graph has out-degree one, and if $M$
  is non-deterministic, then the grpah has outdegree at most two.
  Let $G_{M, x}$ be the configuration graph of a space-$S(n)$ machine $M$ on
  some input $x \st |x| = n$:
  \begin{itemize}
    \item
      Every vertex in $G_{M, x}$ can be described using $cS(n)$ bits for some
      constant $c$ (depending on $M$'s alphabet size and number of tapes) and
      in particular, $G_{M, x}$ has at most $2^{cS(n)}$ vertices.

    \item
      There is an $O(S(n))$-size CNF formula $\varphi_{M, x}$ such that
      for every two strings $C$ and $C^\prime$, we have
      $\varphi_{M, x} (C, C^\prime) = 1$ iff $C$ and $C^\prime$ encode two
      neighboring configurations in $G_{M, x}$.
  \end{itemize}
\end{note}


\subsection*{Chapter 5: The Polynomial Hierarchy and Alterations}



\subsection*{Chapter 6: Boolean Circuits}


\subsection*{Examples}



\end{document}

